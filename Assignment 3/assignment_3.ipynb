{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced programming: assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daniel A.\n",
    "### UID: 100444499"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and Manipulating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "data = pd.read_pickle(\"./data/wind_pickle.pickle\")\n",
    "\n",
    "# dropping cols\n",
    "data.drop(['steps', 'month', 'day', 'hour'], axis=1, inplace=True)\n",
    "\n",
    "# set seed\n",
    "my_NIA = 34291182\n",
    "np.random.seed(my_NIA)\n",
    "\n",
    "# selecting 10% of cols except year and energy\n",
    "cols = list(set(data.columns) - {'year', 'energy'})\n",
    "cols_selected = [np.random.choice(cols) for x in range(int(len(cols)*0.1))]\n",
    "\n",
    "# adding 5% missing values at random places\n",
    "for col in cols_selected:\n",
    "    selected_indexes = [np.random.choice(\n",
    "        data.index) for x in range(int(len(data)*0.05))]\n",
    "    for idx in selected_indexes:\n",
    "        data.loc[idx,col] = np.nan\n",
    "\n",
    "# saving the dataset\n",
    "data.to_pickle('./data/data.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further data preprocessing for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train partition\n",
    "train = data[data['year'].isin([2005,2006])].drop('year',axis=1)\n",
    "X_train = train[[x for x in train.columns if x != 'energy']].values\n",
    "y_train = train['energy'].values\n",
    "# validation partition\n",
    "validation = data[data['year'].isin([2007,2008])].drop('year',axis=1)\n",
    "X_validation = validation[[x for x in train.columns if x != 'energy']].values\n",
    "y_validation = validation['energy'].values\n",
    "# test partition\n",
    "test = data[data['year'].isin([2009,2010])].drop('year',axis=1)\n",
    "X_test = test[[x for x in train.columns if x != 'energy']].values\n",
    "y_test = test['energy'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Model selection and hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and evaluating KNN, Reg trees, SVMs with default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe to keep track of scores and results\n",
    "scores = {'knn':[],'svm':[],'dtr':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define 3 pipelines, one for KNN, another one for SVM and another one for Decision Trees. \n",
    "\n",
    "For KNN and SVM we use imputation (with simple imputer using the mean strategy) and a min max scaler.\n",
    "\n",
    "For Decision trees we only perform imputation and then the model fit.\n",
    "\n",
    "We create a dictionary with each model name as key and each pipeline as value.\n",
    "\n",
    "We then create a loop where we print the name of the model (to know how far the loop has gone) and then we append to the scores dataframe the MAE of each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn\n",
      "svm\n",
      "dtr\n"
     ]
    }
   ],
   "source": [
    "# knn pipeline\n",
    "knn = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', KNeighborsRegressor())])\n",
    "\n",
    "# svm\n",
    "svm = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', SVR())])\n",
    "\n",
    "# tree\n",
    "dtr = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('model', DecisionTreeRegressor())])\n",
    "\n",
    "# models\n",
    "models = {'knn':knn, 'svm':svm, 'dtr':dtr}\n",
    "for name, model in models.items():\n",
    "    print(name)\n",
    "    models[name].fit(X_train, y_train)\n",
    "    scores[name].append(mean_absolute_error(y_test, models[name].predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and evaluating KNN, Reg trees, SVMs with imputation and hyper-parameter tuning using RandomizedSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we define pipelines with the intention to use RandomizedSearch to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For KNN we first define the parameters for steps in the pipeline:\n",
    "\n",
    "For the model we test:\n",
    " - n_neighbors for all values between 2 and 30 with steps of 1\n",
    " - leaf_size for all values between 28 and 40 with steps of 1\n",
    " - algorithm for auto, ball_tree, kd_tree and brute\n",
    " - weights for uniform and distance\n",
    "\n",
    "For the imputer we test:\n",
    " - strategy for mean and median\n",
    "\n",
    "After defining the hyper-parameters to test we define the pipeline with the same steps as before, first imputer, then the scaler and then the model. Then we define the RandomizedSearchCV hyper-parameter tuning with 10 iterations and using MAE for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "knn_params = {\n",
    "    'model__n_neighbors':np.random.random_integers(2,30,1),\n",
    "    'model__leaf_size':np.random.random_integers(28,40,1),\n",
    "    'model__algorithm':['auto','ball_tree','kd_tree','brute'],\n",
    "    'model__weights':['uniform','distance'],\n",
    "    'impute__strategy':['mean','median']\n",
    "}\n",
    "\n",
    "knn = Pipeline([\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', KNeighborsRegressor())])\n",
    "\n",
    "knn_RS = RandomizedSearchCV(estimator=knn,\n",
    "                            param_distributions=knn_params,\n",
    "                            n_iter=10,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SVM we first define the parameters for steps in the pipeline:\n",
    "\n",
    "For the model we test:\n",
    " - degree for all values between 2 and 7 with steps of 1\n",
    " - gamma for all values between 0.0001 and 0.1 with steps of 0.005 along with the scale and auto options\n",
    " - shrinking with True and False\n",
    " - C for all values between 0 and 5 with steps of 0.5\n",
    "\n",
    "For the imputer we test:\n",
    " - strategy for mean and median\n",
    "\n",
    "After defining the hyper-parameters to test we define the pipeline with the same steps as before, first imputer, then the scaler and then the model. Then we define the RandomizedSearchCV hyper-parameter tuning with 10 iterations and using MAE for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm\n",
    "svm_params = {\n",
    "    'model__degree':np.random.random_integers(2,7,1),\n",
    "    'model__gamma':list({'scale','auto'}.union(set(np.arange(0.0001,0.1,0.005)))),\n",
    "    'model__shrinking':[True, False],\n",
    "    'model__C':np.arange(0,5,0.5),\n",
    "    'impute__strategy':['mean','median']\n",
    "}\n",
    "\n",
    "svm = Pipeline([\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', SVR())])\n",
    "\n",
    "\n",
    "svm_RS = RandomizedSearchCV(estimator=svm,\n",
    "                            param_distributions=svm_params,\n",
    "                            n_iter=10,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Decision trees we first define the parameters for steps in the pipeline:\n",
    "\n",
    "For the model we test:\n",
    " - criterion for mse, friedman_mse, mae and poisson\n",
    " - splitter for best and random\n",
    " - max_dept for all values between 2 and 14 with steps of 2\n",
    " - min_samples_split for all values between 2 and 10 with steps of 2\n",
    " - min_samples_leaf for all values between 1 and 10 with steps of 1\n",
    " - max_features for auto, sqrt and log2\n",
    "\n",
    "For the imputer we test:\n",
    " - strategy for mean and median\n",
    "\n",
    "After defining the hyper-parameters to test we define the pipeline with the same steps as before, first imputer, then the scaler and then the model. Then we define the RandomizedSearchCV hyper-parameter tuning with 10 iterations and using MAE for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree\n",
    "dtr_params = {\n",
    "    'model__criterion':['mse', 'friedman_mse', 'mae', 'poisson'],\n",
    "    'model__splitter':['best','random'],\n",
    "    'model__max_depth':np.arange(2,14,2),\n",
    "    'model__min_samples_split':np.arange(2,10,2),\n",
    "    'model__min_samples_leaf':np.arange(1,10,1),\n",
    "    'model__max_features':['auto','sqrt','log2'],\n",
    "    'impute__strategy':['mean','median'],\n",
    "}\n",
    "\n",
    "dtr = Pipeline([\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('model', DecisionTreeRegressor())])\n",
    "\n",
    "dtr_RS = RandomizedSearchCV(estimator=dtr,\n",
    "                            param_distributions=dtr_params,\n",
    "                            n_iter=10,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we loop over the model names (keys of the models dictionary) and the RandomizedSearchCV corresponding to each model's pipeline (values of the models dictionary). We fit using the RandomizedSearchCV and add the mean absolute error to the scores dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn\n",
      "svm\n",
      "dtr\n"
     ]
    }
   ],
   "source": [
    "# models\n",
    "models = {'knn':knn_RS, 'svm':svm_RS, 'dtr':dtr_RS}\n",
    "\n",
    "# running fit\n",
    "for name, model in models.items():\n",
    "    print(name)\n",
    "    models[name].fit(X_train, y_train)\n",
    "    scores[name].append(mean_absolute_error(y_test, models[name].predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking scores for the 6 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row 0 are the models with default params and Row 1 are the models with hyperparameter tuning done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>knn</th>\n      <th>svm</th>\n      <th>dtr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>365.651736</td>\n      <td>517.556690</td>\n      <td>396.987431</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>363.807967</td>\n      <td>482.167105</td>\n      <td>324.342324</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "          knn         svm         dtr\n0  365.651736  517.556690  396.987431\n1  363.807967  482.167105  324.342324"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the MAE,0 the best model is the decision trees with hyperparameter tuning done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Attribute selection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}