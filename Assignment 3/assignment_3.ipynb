{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced programming: assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daniel A.\n",
    "### UID: 100444499"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, PredefinedSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils.validation import check_is_fitted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and Manipulating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the data\n",
    "data = pd.read_pickle(\"./data/wind_pickle.pickle\")\n",
    "\n",
    "# dropping cols\n",
    "data.drop(['steps', 'month', 'day', 'hour'], axis=1, inplace=True)\n",
    "\n",
    "# set seed\n",
    "my_NIA = 34291182\n",
    "np.random.seed(my_NIA)\n",
    "\n",
    "# selecting 10% of cols except year and energy\n",
    "cols = list(set(data.columns) - {'year', 'energy'})\n",
    "cols_selected = [np.random.choice(cols) for x in range(int(len(cols)*0.1))]\n",
    "\n",
    "# adding 5% missing values at random places\n",
    "for col in cols_selected:\n",
    "    selected_indexes = [np.random.choice(\n",
    "        data.index) for x in range(int(len(data)*0.05))]\n",
    "    for idx in selected_indexes:\n",
    "        data.loc[idx,col] = np.nan\n",
    "\n",
    "# saving the dataset\n",
    "data.to_pickle('./data/data.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further data preprocessing for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train partition\n",
    "train = data[data['year'].isin([2005,2006])].drop('year',axis=1)\n",
    "X_train = train[[x for x in train.columns if x != 'energy']].values\n",
    "y_train = train['energy'].values\n",
    "# validation partition\n",
    "validation = data[data['year'].isin([2007,2008])].drop('year',axis=1)\n",
    "X_validation = validation[[x for x in train.columns if x != 'energy']].values\n",
    "y_validation = validation['energy'].values\n",
    "# test partition\n",
    "test = data[data['year'].isin([2009,2010])].drop('year',axis=1)\n",
    "X_test = test[[x for x in train.columns if x != 'energy']].values\n",
    "y_test = test['energy'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Model selection and hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and evaluating KNN, Reg trees, SVMs with default hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe to keep track of scores and results\n",
    "scores = {'knn':[],'svm':[],'dtr':[]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define 3 pipelines, one for KNN, another one for SVM and another one for Decision Trees. \n",
    "\n",
    "For KNN and SVM we use imputation (with simple imputer using the mean strategy) and a min max scaler.\n",
    "\n",
    "For Decision trees we only perform imputation and then the model fit.\n",
    "\n",
    "We create a dictionary with each model name as key and each pipeline as value.\n",
    "\n",
    "We then create a loop where we print the name of the model (to know how far the loop has gone) and then we append to the scores dataframe the MAE of each prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn\n",
      "svm\n",
      "dtr\n"
     ]
    }
   ],
   "source": [
    "# knn pipeline\n",
    "knn = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', KNeighborsRegressor())])\n",
    "\n",
    "# svm\n",
    "svm = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', SVR())])\n",
    "\n",
    "# tree\n",
    "dtr = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy='mean')),\n",
    "    ('model', DecisionTreeRegressor())])\n",
    "\n",
    "# models\n",
    "models = {'knn':knn, 'svm':svm, 'dtr':dtr}\n",
    "for name, model in models.items():\n",
    "    print(name)\n",
    "    models[name].fit(X_train, y_train)\n",
    "    scores[name].append(mean_absolute_error(y_test, models[name].predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and evaluating KNN, Reg trees, SVMs with imputation and hyper-parameter tuning using RandomizedSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a predefined split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indeces = np.zeros(X_validation.shape[0])\n",
    "val_indeces[:round(2/3*X_validation.shape[0])] = -1\n",
    "pdfsplit = PredefinedSplit(val_indeces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we define pipelines with the intention to use RandomizedSearch to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For KNN we first define the parameters for steps in the pipeline:\n",
    "\n",
    "For the model we test:\n",
    " - n_neighbors for all values between 2 and 30 with steps of 1\n",
    " - leaf_size for all values between 28 and 40 with steps of 1\n",
    " - algorithm for auto, ball_tree, kd_tree and brute\n",
    " - weights for uniform and distance\n",
    "\n",
    "For the imputer we test:\n",
    " - strategy for mean and median\n",
    "\n",
    "After defining the hyper-parameters to test we define the pipeline with the same steps as before, first imputer, then the scaler and then the model. Then we define the RandomizedSearchCV hyper-parameter tuning with 10 iterations and using MAE for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "knn_params = {\n",
    "    'model__n_neighbors':np.arange(2,30,1),\n",
    "    'model__leaf_size':np.arange(28,40,1),\n",
    "    'model__algorithm':['auto','ball_tree','kd_tree','brute'],\n",
    "    'model__weights':['uniform','distance'],\n",
    "    'impute__strategy':['mean','median']\n",
    "}\n",
    "\n",
    "knn = Pipeline([\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', KNeighborsRegressor())])\n",
    "\n",
    "knn_RS = RandomizedSearchCV(estimator=knn,\n",
    "                            param_distributions=knn_params,\n",
    "                            n_iter=10,\n",
    "                            cv=pdfsplit,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SVM we first define the parameters for steps in the pipeline:\n",
    "\n",
    "For the model we test:\n",
    " - degree for all values between 2 and 7 with steps of 1\n",
    " - gamma for all values between 0.0001 and 0.1 with steps of 0.005 along with the scale and auto options\n",
    " - shrinking with True and False\n",
    " - C for all values between 0 and 5 with steps of 0.5\n",
    "\n",
    "For the imputer we test:\n",
    " - strategy for mean and median\n",
    "\n",
    "After defining the hyper-parameters to test we define the pipeline with the same steps as before, first imputer, then the scaler and then the model. Then we define the RandomizedSearchCV hyper-parameter tuning with 10 iterations and using MAE for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm\n",
    "svm_params = {\n",
    "    'model__degree':np.arange(2,7,1),\n",
    "    'model__gamma':list({'scale','auto'}.union(set(np.arange(0.0001,0.1,0.005)))),\n",
    "    'model__shrinking':[True, False],\n",
    "    'model__C':np.arange(0,5,0.5),\n",
    "    'impute__strategy':['mean','median']\n",
    "}\n",
    "\n",
    "svm = Pipeline([\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('model', SVR())])\n",
    "\n",
    "\n",
    "svm_RS = RandomizedSearchCV(estimator=svm,\n",
    "                            param_distributions=svm_params,\n",
    "                            n_iter=10,\n",
    "                            cv=pdfsplit,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Decision trees we first define the parameters for steps in the pipeline:\n",
    "\n",
    "For the model we test:\n",
    " - criterion for mse, friedman_mse, mae and poisson\n",
    " - splitter for best and random\n",
    " - max_dept for all values between 2 and 14 with steps of 2\n",
    " - min_samples_split for all values between 2 and 10 with steps of 2\n",
    " - min_samples_leaf for all values between 1 and 10 with steps of 1\n",
    " - max_features for auto, sqrt and log2\n",
    "\n",
    "For the imputer we test:\n",
    " - strategy for mean and median\n",
    "\n",
    "After defining the hyper-parameters to test we define the pipeline with the same steps as before, first imputer, then the scaler and then the model. Then we define the RandomizedSearchCV hyper-parameter tuning with 10 iterations and using MAE for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree\n",
    "dtr_params = {\n",
    "    'model__criterion':['mse', 'friedman_mse', 'mae', 'poisson'],\n",
    "    'model__splitter':['best','random'],\n",
    "    'model__max_depth':np.arange(2,14,2),\n",
    "    'model__min_samples_split':np.arange(2,10,2),\n",
    "    'model__min_samples_leaf':np.arange(1,10,1),\n",
    "    'model__max_features':['auto','sqrt','log2'],\n",
    "    'impute__strategy':['mean','median'],\n",
    "}\n",
    "\n",
    "dtr = Pipeline([\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('model', DecisionTreeRegressor())])\n",
    "\n",
    "dtr_RS = RandomizedSearchCV(estimator=dtr,\n",
    "                            param_distributions=dtr_params,\n",
    "                            n_iter=10,\n",
    "                            cv=pdfsplit,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we loop over the model names (keys of the models dictionary) and the RandomizedSearchCV corresponding to each model's pipeline (values of the models dictionary). We fit using the RandomizedSearchCV and add the mean absolute error to the scores dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn\n",
      "svm\n",
      "dtr\n"
     ]
    }
   ],
   "source": [
    "# models\n",
    "models = {'knn':knn_RS, 'svm':svm_RS, 'dtr':dtr_RS}\n",
    "\n",
    "# running fit\n",
    "for name, model in models.items():\n",
    "    print(name)\n",
    "    models[name].fit(X_train, y_train)\n",
    "    scores[name].append(mean_absolute_error(y_test, models[name].predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking scores for the 6 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row 0 are the models with default params and Row 1 are the models with hyperparameter tuning done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>knn</th>\n      <th>svm</th>\n      <th>dtr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>363.636970</td>\n      <td>517.567987</td>\n      <td>393.728190</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>366.139236</td>\n      <td>469.443647</td>\n      <td>323.745465</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "          knn         svm         dtr\n0  363.636970  517.567987  393.728190\n1  366.139236  469.443647  323.745465"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our models with hyper-parameter tuning yield better results with out model with the lowest MAE (323.745465) being the decision tree with hyper-parameter tuning done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the MAE,0 the best model is the decision trees with hyperparameter tuning done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Attribute selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First pipeline: SelectKBest included in the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first Pipeline we define the parameters for steps in the pipeline:\n",
    "\n",
    "For the model we test:\n",
    " - n_neighbors between 2 and 50 with steps of 1\n",
    "  \n",
    "For the feature selection (SelectKBest):\n",
    " - k between 2 and 40 with steps of 1 and the 'all' parameter (which just tries all features)\n",
    "\n",
    "For the imputer we test:\n",
    " - strategy for mean and median\n",
    "\n",
    "After defining the hyper-parameters to test we define the pipeline with the same steps as before, first imputer, then the scaler and then the model. Then we define the RandomizedSearchCV hyper-parameter tuning with 25 iterations and using MAE for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "knn_params_1 = {\n",
    "    'model__n_neighbors':np.arange(2,50,1),\n",
    "    'featsel__k':list(set(np.arange(2,40,1)).union({'all'})),\n",
    "    'impute__strategy':['mean','median']\n",
    "}\n",
    "\n",
    "knn_1 = Pipeline([\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('featsel',SelectKBest()),\n",
    "    ('model', KNeighborsRegressor())])\n",
    "\n",
    "knn_RS_1 = RandomizedSearchCV(estimator=knn_1,\n",
    "                            param_distributions=knn_params_1,\n",
    "                            n_iter=25,\n",
    "                            cv=pdfsplit,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second pipeline: PCA included in the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second Pipeline we define the parameters for steps in the pipeline:\n",
    "\n",
    "For the model we test:\n",
    " - n_neighbors between 2 and 50 with steps of 1\n",
    "  \n",
    "For the variable decomposition (PCA):\n",
    " - k between 2 and 40 with steps of 1 and the 'all' parameter (which just tries all features)\n",
    "\n",
    "For the imputer we test:\n",
    " - strategy for mean and median\n",
    "\n",
    "After defining the hyper-parameters to test we define the pipeline with the same steps as before, first imputer, then the scaler and then the model. Then we define the RandomizedSearchCV hyper-parameter tuning with 10 iterations and using MAE for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "knn_params_2 = {\n",
    "    'model__n_neighbors':np.arange(2,50,1),\n",
    "    'decomp__n_components':list(set(np.arange(2,40,1)).union({'all','mle'})),\n",
    "    'impute__strategy':['mean','median']\n",
    "}\n",
    "\n",
    "knn_2 = Pipeline([\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('decomp',PCA()),\n",
    "    ('model', KNeighborsRegressor())])\n",
    "\n",
    "knn_RS_2 = RandomizedSearchCV(estimator=knn_2,\n",
    "                            param_distributions=knn_params_2,\n",
    "                            n_iter=10,\n",
    "                            cv=pdfsplit,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third pipeline: both PCA and SelectKBest included in the pipeline (running SelectKBest first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the third Pipeline we define the parameters for steps in the pipeline:\n",
    "\n",
    "For the model we test:\n",
    " - n_neighbors between 2 and 50 with steps of 1\n",
    "  \n",
    "For the feature selection (SelectKBest):\n",
    " - k between 2 and 40 with steps of 1 and the 'all' parameter (which just tries all features)\n",
    "\n",
    "For the variable decomposition (PCA):\n",
    " - k between 2 and 40 with steps of 1 and the 'all' parameter (which just tries all features) and 'mle'\n",
    "\n",
    "For the imputer we test:\n",
    " - strategy for mean and median\n",
    "\n",
    "After defining the hyper-parameters to test we define the pipeline with the same steps as before, first imputer, then the scaler and then the model. Then we define the RandomizedSearchCV hyper-parameter tuning with 10 iterations and using MAE for scoring.\n",
    "\n",
    "For this pipeline we run the feature selection before the variable decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "knn_params_3 = {\n",
    "    'model__n_neighbors':np.arange(2,50,1),\n",
    "    'featsel__k':list(set(np.arange(2,40,1)).union({'all'})),\n",
    "    'decomp__n_components':list(set(np.arange(2,40,1)).union({'all','mle'})),\n",
    "    'impute__strategy':['mean','median']\n",
    "}\n",
    "\n",
    "knn_3 = Pipeline([\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('featsel',SelectKBest()),\n",
    "    ('decomp',PCA()),\n",
    "    ('model', KNeighborsRegressor())])\n",
    "\n",
    "knn_RS_3 = RandomizedSearchCV(estimator=knn_3,\n",
    "                            param_distributions=knn_params_3,\n",
    "                            n_iter=10,\n",
    "                            cv=pdfsplit,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourth pipeline: both PCA and SelectKBest included in the pipeline (running PCA first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the fourth Pipeline we define the parameters for steps in the pipeline:\n",
    "\n",
    "For the model we test:\n",
    " - n_neighbors between 2 and 50 with steps of 1\n",
    "  \n",
    "For the feature selection (SelectKBest):\n",
    " - k between 2 and 40 with steps of 1 and the 'all' parameter (which just tries all features)\n",
    "\n",
    "For the variable decomposition (PCA):\n",
    " - k between 2 and 40 with steps of 1 and the 'all' parameter (which just tries all features) and 'mle'\n",
    "\n",
    "For the imputer we test:\n",
    " - strategy for mean and median\n",
    "\n",
    "After defining the hyper-parameters to test we define the pipeline with the same steps as before, first imputer, then the scaler and then the model. Then we define the RandomizedSearchCV hyper-parameter tuning with 10 iterations and using MAE for scoring.\n",
    "\n",
    "For this pipeline we run the the variable decomposition before the feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn\n",
    "knn_params_4 = {\n",
    "    'model__n_neighbors':np.arange(2,50,1),\n",
    "    'decomp__n_components':list(set(np.arange(2,40,1)).union({'all','mle'})),\n",
    "    'featsel__k':list(set(np.arange(2,40,1)).union({'all'})),\n",
    "    'impute__strategy':['mean','median']\n",
    "}\n",
    "\n",
    "knn_4 = Pipeline([\n",
    "    ('impute', SimpleImputer()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('decomp',PCA()),\n",
    "    ('featsel',SelectKBest()),\n",
    "    ('model', KNeighborsRegressor())])\n",
    "\n",
    "knn_RS_4 = RandomizedSearchCV(estimator=knn_4,\n",
    "                            param_distributions=knn_params_4,\n",
    "                            n_iter=10,\n",
    "                            cv=pdfsplit,\n",
    "                            scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the models in the same manner as before, we have 4 instances of RandomizedSearchCV and we append the MAE of the models to the datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_1\n",
      "knn_2\n",
      "knn_3\n",
      "knn_4\n"
     ]
    }
   ],
   "source": [
    "# creating a dataframe to keep track of scores and results\n",
    "scores = {'pipeline':[],'knn':[]}\n",
    "\n",
    "# models\n",
    "models = {'knn_1':knn_RS_1, 'knn_2':knn_RS_2, 'knn_3':knn_RS_3, 'knn_4':knn_RS_4}\n",
    "\n",
    "# running fit\n",
    "for idx, (name, model) in enumerate(models.items()):\n",
    "    print(name)\n",
    "    models[name].fit(X_train, y_train)\n",
    "    scores['pipeline'].append(idx + 1)\n",
    "    scores['knn'].append(mean_absolute_error(y_test, models[name].predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we see our scores below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pipeline</th>\n      <th>knn</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>376.815078</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>361.083188</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>367.272739</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>419.986353</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   pipeline         knn\n0         1  376.815078\n1         2  361.083188\n2         3  367.272739\n3         4  419.986353"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that the best pipeline is the second one we tried, it gets the lowest MAE, closely followed by the first pipeline, however, it does not improve on the previous decision tree regressor result. \n",
    "\n",
    "We could therefore say that tuning a decision tree regressor might be more worthwhile than tuning a KNN model extensively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting best features from the first pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from our first pipeline the selected columns are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['iews.1', 'iews.2', 'iews.3', 'iews.7', 'iews.8', 'iews.12', 'iews.13',\n       'iews.17', 'iews.18', 'iews.24', 'iews.25', 'inss.1', 'inss.2',\n       'inss.3', 'inss.4', 'inss.5', 'inss.6', 'inss.7', 'inss.8', 'inss.9',\n       'inss.10', 'inss.11', 'inss.12', 'inss.13', 'inss.14', 'inss.15',\n       'inss.16', 'inss.17', 'inss.18', 'inss.19', 'inss.20', 'inss.21',\n       'inss.22', 'inss.23'],\n      dtype='object')"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sup = models['knn_1'].best_estimator_.named_steps['featsel'].get_support(indices=True)\n",
    "feats = data.iloc[:,sup]\n",
    "feats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "34"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feats.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that among the most common locations selected by the model (using k=34 as selected by the hyper parameter tuning), the sotavento location is present twice (iews.13 and inss.13), there's also other locations present twice, as the tuning only chooses Instantaneous eastward turbulent surface stress and Instantaneous northward turbulent surface, for these 2 types of metrics, the most common locations are:\n",
    " - 1\n",
    " - 2\n",
    " - 3\n",
    " - 7\n",
    " - 8\n",
    " - 12\n",
    " - 13\n",
    " - 17\n",
    " - 18"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}