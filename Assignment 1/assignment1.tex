\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provides euro and other symbols
\else % if luatex or xelatex
  \usepackage{unicode-math}
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\usepackage{hyperref}
\hypersetup{
            pdftitle={Assignmment 1},
            pdfauthor={Daniel Alonso},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{0}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother


\title{Assignmment 1}
\author{Daniel Alonso}
\date{November 20th, 2020}

\begin{document}
\maketitle

Importing libraries

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(Rcpp)}
\KeywordTok{library}\NormalTok{(microbenchmark)}
\KeywordTok{library}\NormalTok{(foreach)}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercise-1}{%
\section{Exercise 1}\label{exercise-1}}

\hypertarget{class-example-this-code-is-not-mine}{%
\subsection{Class example (this code is NOT
mine)}\label{class-example-this-code-is-not-mine}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_knn_R =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(X, X0, y)\{}
  \CommentTok{# X data matrix with input attributes}
  \CommentTok{# y response variable values of instances in X  }
  \CommentTok{# X0 vector of input attributes for prediction}
  
\NormalTok{  nrows =}\StringTok{ }\KeywordTok{nrow}\NormalTok{(X)}
\NormalTok{  ncols =}\StringTok{ }\KeywordTok{ncol}\NormalTok{(X)}
  
  \CommentTok{# One of the instances is going to be the closest one:}
  \CommentTok{# closest_distance: it is the distance , min_output}
\NormalTok{  closest_distance =}\StringTok{ }\DecValTok{99999999}
\NormalTok{  closest_output =}\StringTok{ }\DecValTok{-1}
\NormalTok{  closest_neighbor =}\StringTok{ }\DecValTok{-1}
  
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{nrows) \{}

\NormalTok{    distance =}\StringTok{ }\DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{ncols) \{}
\NormalTok{      difference =}\StringTok{ }\NormalTok{X[i,j]}\OperatorTok{-}\NormalTok{X0[j]}
\NormalTok{      distance =}\StringTok{ }\NormalTok{distance }\OperatorTok{+}\StringTok{ }\NormalTok{difference }\OperatorTok{*}\StringTok{ }\NormalTok{difference}
\NormalTok{    \}}
    
\NormalTok{    distance =}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(distance)}
    
    \ControlFlowTok{if}\NormalTok{ (distance }\OperatorTok{<}\StringTok{ }\NormalTok{closest_distance) \{}
\NormalTok{      closest_distance =}\StringTok{ }\NormalTok{distance}
\NormalTok{      closest_output =}\StringTok{ }\NormalTok{y[i]}
\NormalTok{      closest_neighbor =}\StringTok{ }\NormalTok{i}
\NormalTok{    \}}
\NormalTok{  \}}
\NormalTok{  closest_output}
\NormalTok{\}  }
\end{Highlighting}
\end{Shaded}

\hypertarget{testing-class-example-this-code-is-not-mine}{%
\subsection{Testing class example (This code is NOT
mine)}\label{testing-class-example-this-code-is-not-mine}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# X contains the inputs as a matrix of real numbers}
\KeywordTok{data}\NormalTok{(}\StringTok{"iris"}\NormalTok{)}
\CommentTok{# X contains the input attributes (excluding the class)}
\NormalTok{X <-}\StringTok{ }\NormalTok{iris[,}\OperatorTok{-}\DecValTok{5}\NormalTok{]}
\CommentTok{# y contains the response variable (named medv, a numeric value)}
\NormalTok{y <-}\StringTok{ }\NormalTok{iris[,}\DecValTok{5}\NormalTok{]}
\CommentTok{# From dataframe to matrix}
\NormalTok{X <-}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(X)}
\CommentTok{# From factor to integer}
\NormalTok{y <-}\StringTok{ }\KeywordTok{as.integer}\NormalTok{(y)}
\CommentTok{# This is the point we want to predict}
\NormalTok{X0 <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\FloatTok{5.80}\NormalTok{, }\FloatTok{3.00}\NormalTok{, }\FloatTok{4.35}\NormalTok{, }\FloatTok{1.30}\NormalTok{)}
\CommentTok{# Using my_knn and FNN:knn to predict point X0}
\CommentTok{# Using the same number of neighbors, it should be similar (k=1)}
\KeywordTok{my_knn_R}\NormalTok{(X, X0, y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(FNN)}
\NormalTok{FNN}\OperatorTok{::}\KeywordTok{knn}\NormalTok{(X, }\KeywordTok{matrix}\NormalTok{(X0, }\DataTypeTok{nrow =} \DecValTok{1}\NormalTok{), y, }\DataTypeTok{k=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
## attr(,"nn.index")
##      [,1]
## [1,]   96
## attr(,"nn.dist")
##           [,1]
## [1,] 0.2061553
## Levels: 2
\end{verbatim}

\newpage

\hypertarget{translating-the-teachers-code-into-c-into-an-rccp-function}{%
\subsection{Translating the teacher's code into C++ into an Rccp
function}\label{translating-the-teachers-code-into-c-into-an-rccp-function}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cppFunction}\NormalTok{(}\StringTok{'}
\StringTok{int knn_1(NumericMatrix X, NumericVector X0, NumericVector y) \{}
\StringTok{    int nrows = X.nrow();}
\StringTok{    int ncols = X.ncol();}

\StringTok{    double closest_distance = 99999999;}
\StringTok{    double closest_output = -1;}
\StringTok{    double closest_neighbor = -1;}
\StringTok{    double difference = 0;}

\StringTok{    int i;}
\StringTok{    int j;}

\StringTok{    for (i = 0; i < nrows; i++) \{}
\StringTok{        }
\StringTok{        double distance = 0;}
\StringTok{        for (j = 0; j < ncols; j++) \{}
\StringTok{            difference = X(i,j) - X0(j);}
\StringTok{            distance = distance + difference * difference;}
\StringTok{        \}}

\StringTok{        distance = sqrt(distance);}

\StringTok{        if (distance < closest_distance) \{}
\StringTok{            closest_distance = distance;}
\StringTok{            closest_output = y(i);}
\StringTok{            closest_neighbor = i;}
\StringTok{        \}}
\StringTok{    \}}
\StringTok{    return closest_output;}
\StringTok{\}'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{testing-rcpp-translation}{%
\subsection{Testing Rcpp translation}\label{testing-rcpp-translation}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{knn_1}\NormalTok{(X, X0, y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(FNN)}
\NormalTok{FNN}\OperatorTok{::}\KeywordTok{knn}\NormalTok{(X, }\KeywordTok{matrix}\NormalTok{(X0, }\DataTypeTok{nrow =} \DecValTok{1}\NormalTok{), y, }\DataTypeTok{k=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
## attr(,"nn.index")
##      [,1]
## [1,]   96
## attr(,"nn.dist")
##           [,1]
## [1,] 0.2061553
## Levels: 2
\end{verbatim}

\hypertarget{benchmarking-differences-in-runtime-between-r-version-and-rcpp-version}{%
\subsection{Benchmarking differences in runtime between R version and
Rcpp
version}\label{benchmarking-differences-in-runtime-between-r-version-and-rcpp-version}}

\hypertarget{r-version}{%
\subsubsection{R version}\label{r-version}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{microbenchmark}\NormalTok{(}\KeywordTok{my_knn_R}\NormalTok{(X, X0, y))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Unit: microseconds
##                expr     min       lq     mean  median       uq      max neval
##  my_knn_R(X, X0, y) 694.301 726.2015 763.1643 741.662 766.6315 2225.033   100
\end{verbatim}

We can see that our mean runtime for the R version is more than 800
microseconds

\hypertarget{fnn-version}{%
\subsubsection{FNN version}\label{fnn-version}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{microbenchmark}\NormalTok{(FNN}\OperatorTok{::}\KeywordTok{knn}\NormalTok{(X, }\KeywordTok{matrix}\NormalTok{(X0, }\DataTypeTok{nrow =} \DecValTok{1}\NormalTok{), y, }\DataTypeTok{k=}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Unit: microseconds
##                                         expr     min      lq    mean   median
##  FNN::knn(X, matrix(X0, nrow = 1), y, k = 1) 224.161 227.811 238.629 231.1565
##       uq     max neval
##  239.076 435.271   100
\end{verbatim}

We can see that our mean runtime for the Rcpp version is of under 250
microseconds

\hypertarget{rcpp-version}{%
\subsubsection{Rcpp version}\label{rcpp-version}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{microbenchmark}\NormalTok{(}\KeywordTok{knn_1}\NormalTok{(X, X0, y))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Unit: microseconds
##             expr   min    lq     mean median     uq     max neval
##  knn_1(X, X0, y) 4.271 4.441 14.21771  4.491 4.6005 973.851   100
\end{verbatim}

We can see that our mean runtime for the Rcpp version is of under 14
microseconds

\hypertarget{exercise-2}{%
\section{Exercise 2}\label{exercise-2}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knn_more =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(X, X0, y, K)\{}
  \CommentTok{# X data matrix with input attributes}
  \CommentTok{# y response variable values of instances in X  }
  \CommentTok{# X0 vector of input attributes for prediction}
  
\NormalTok{  nrows =}\StringTok{ }\KeywordTok{nrow}\NormalTok{(X)}
\NormalTok{  ncols =}\StringTok{ }\KeywordTok{ncol}\NormalTok{(X)}
  
  \CommentTok{# One of the instances is going to be the closest one:}
  \CommentTok{# closest_distance: it is the distance , min_output}
\NormalTok{  distances =}\StringTok{ }\KeywordTok{c}\NormalTok{()}
\NormalTok{  closest_distance =}\StringTok{ }\FloatTok{1e99}
\NormalTok{  closest_neighbor =}\StringTok{ }\DecValTok{-1}
\NormalTok{  closest_classif =}\StringTok{ }\DecValTok{-1}
  
  \CommentTok{# get distances}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{nrows) \{}

\NormalTok{    distance =}\StringTok{ }\DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{ncols) \{}
\NormalTok{      difference =}\StringTok{ }\NormalTok{X[i,j]}\OperatorTok{-}\NormalTok{X0[j]}
\NormalTok{      distance =}\StringTok{ }\NormalTok{distance }\OperatorTok{+}\StringTok{ }\NormalTok{difference }\OperatorTok{*}\StringTok{ }\NormalTok{difference}
\NormalTok{    \}}
    
\NormalTok{    distance =}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(distance)}

    \CommentTok{# add distance to vector}
\NormalTok{    distances =}\StringTok{ }\KeywordTok{c}\NormalTok{(distances, distance)}

    \ControlFlowTok{if}\NormalTok{ (distance }\OperatorTok{<}\StringTok{ }\NormalTok{closest_distance) \{}
\NormalTok{      closest_distance =}\StringTok{ }\NormalTok{distance}
\NormalTok{      closest_classif =}\StringTok{ }\NormalTok{y[i]}
\NormalTok{      closest_neighbor =}\StringTok{ }\NormalTok{i}
\NormalTok{    \}}
\NormalTok{  \}}

  \CommentTok{# eliminating closest distance}
\NormalTok{  NN_distances =}\StringTok{ }\KeywordTok{c}\NormalTok{(closest_distance)}
\NormalTok{  NN_classif =}\StringTok{ }\KeywordTok{c}\NormalTok{(closest_classif)}
\NormalTok{  distances[closest_neighbor] =}\StringTok{ }\FloatTok{1e99}
\NormalTok{  distances =}\StringTok{ }\KeywordTok{unname}\NormalTok{(distances)}

  \CommentTok{# We already got the closest so remove one from K}
\NormalTok{  K =}\StringTok{ }\NormalTok{K }\OperatorTok{-}\StringTok{ }\DecValTok{1}
  
  \CommentTok{# because we can't sort, we just manually pull out the minimum value K times}
  \CommentTok{# by subtracting each distance to the previous closest distance}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{K) \{}

    \CommentTok{# placeholder variables for loop}
\NormalTok{    diff =}\StringTok{ }\DecValTok{0}
\NormalTok{    min_diff =}\StringTok{ }\FloatTok{1e99}
\NormalTok{    index =}\StringTok{ }\DecValTok{0}

    \CommentTok{# calculate diffs between distances and closest distance}
    \CommentTok{# the lowest is saved in placeholder variable min_diff}
    \CommentTok{# then the index is saved in the index variable}
    \ControlFlowTok{for}\NormalTok{ (idx }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{nrows) \{}
\NormalTok{      diff =}\StringTok{ }\NormalTok{distances[idx] }\OperatorTok{-}\StringTok{ }\NormalTok{NN_distances[i]}
      \ControlFlowTok{if}\NormalTok{ (diff }\OperatorTok{<}\StringTok{ }\NormalTok{min_diff) \{}
\NormalTok{        min_diff =}\StringTok{ }\NormalTok{diff}
\NormalTok{        index =}\StringTok{ }\NormalTok{idx}
\NormalTok{      \}}
\NormalTok{    \}}

    \CommentTok{# add the corresponding distance to NN distances}
    \CommentTok{# add the corresponding classif to NN classif}
\NormalTok{    NN_distances =}\StringTok{ }\KeywordTok{c}\NormalTok{(NN_distances, distances[index])}
\NormalTok{    NN_classif =}\StringTok{ }\KeywordTok{c}\NormalTok{(NN_classif, y[index])}
\NormalTok{    distances[index] =}\StringTok{ }\FloatTok{1e99}
\NormalTok{  \}}

  \CommentTok{# different classifications}
\NormalTok{  classifs =}\StringTok{ }\KeywordTok{unique}\NormalTok{(y)}

  \CommentTok{# loop through classifications to count}
\NormalTok{  cnts =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{6}\NormalTok{), }\DataTypeTok{nrow=}\KeywordTok{length}\NormalTok{(classifs), }\DataTypeTok{byrow=}\OtherTok{TRUE}\NormalTok{)}
\NormalTok{  cnts[,}\DecValTok{1}\NormalTok{] =}\StringTok{ }\NormalTok{classifs;}
  \ControlFlowTok{for}\NormalTok{ (g }\ControlFlowTok{in}\NormalTok{ NN_classif) \{}
\NormalTok{    cnts[g,}\DecValTok{2}\NormalTok{] =}\StringTok{ }\NormalTok{cnts[g,}\DecValTok{2}\NormalTok{] }\OperatorTok{+}\StringTok{ }\DecValTok{1}
\NormalTok{  \}}

  \CommentTok{# check if there's identical counts}
\NormalTok{  count_vector =}\StringTok{ }\NormalTok{cnts[,}\DecValTok{2}\NormalTok{]}
\NormalTok{  group_normally =}\StringTok{ }\DecValTok{0}
  \ControlFlowTok{if}\NormalTok{ (K }\OperatorTok{<=}\StringTok{ }\KeywordTok{length}\NormalTok{(classifs)) \{}
    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{length}\NormalTok{(count_vector[count_vector }\OperatorTok{==}\StringTok{ }\KeywordTok{max}\NormalTok{(count_vector)]) }\OperatorTok{>}\StringTok{ }\DecValTok{1}\NormalTok{) \{}
      \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{K) \{}
        \ControlFlowTok{if}\NormalTok{ (NN_distances[i] }\OperatorTok{==}\StringTok{ }\KeywordTok{min}\NormalTok{(NN_distances)) \{}
\NormalTok{          group =}\StringTok{ }\NormalTok{NN_classif[i]}
\NormalTok{        \}}
\NormalTok{      \}}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      group_normally =}\StringTok{ }\DecValTok{1}
\NormalTok{    \} }
\NormalTok{  \} }
  \ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    group_normally =}\StringTok{ }\DecValTok{1}
\NormalTok{  \}}
  
  \CommentTok{# select maximum value}
  \ControlFlowTok{if}\NormalTok{ (group_normally }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{) \{}
\NormalTok{    group =}\StringTok{ }\DecValTok{0}
    \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in}\NormalTok{ cnts[,}\DecValTok{1}\NormalTok{]) \{}
      \ControlFlowTok{if}\NormalTok{ (count_vector[i] }\OperatorTok{==}\StringTok{ }\KeywordTok{max}\NormalTok{(count_vector)) \{}
\NormalTok{        group =}\StringTok{ }\NormalTok{i}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}

\NormalTok{  group}
\NormalTok{\}  }
\NormalTok{test <-}\StringTok{ }\KeywordTok{knn_more}\NormalTok{(X, X0, y, }\DecValTok{3}\NormalTok{)}
\NormalTok{test}
\end{Highlighting}
\end{Shaded}

\hypertarget{translating-the-teacher-code-into-c-into-an-rccp-function}{%
\subsection{Translating the teacher code into C++ into an Rccp
function}\label{translating-the-teacher-code-into-c-into-an-rccp-function}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{cppFunction}\NormalTok{(}\StringTok{'}
\StringTok{int knn_more(NumericMatrix X, NumericVector X0, NumericVector y, int K) \{}
\StringTok{    int nrows = X.nrow();}
\StringTok{    int ncols = X.ncol();}

\StringTok{    NumericVector distances(nrows);}
\StringTok{    NumericVector NN_distances(K);}
\StringTok{    NumericVector NN_classif(K);}
\StringTok{    double closest_distance = 99999999999999999;}
\StringTok{    double closest_output = -1;}
\StringTok{    double closest_neighbor = -1;}
\StringTok{    double difference;}

\StringTok{    int i;}
\StringTok{    int j;}
\StringTok{    }

\StringTok{    for (i = 0; i < nrows; i++) \{}
\StringTok{        }
\StringTok{        double distance = 0;}
\StringTok{        for (j = 0; j < ncols; j++) \{}
\StringTok{            difference = X(i,j) - X0(j);}
\StringTok{            distance = distance + difference * difference;}
\StringTok{        \}}

\StringTok{        distance = sqrt(distance);}
\StringTok{        distances[i] = distance;}

\StringTok{        if (distance < closest_distance) \{}
\StringTok{            closest_distance = distance;}
\StringTok{            closest_output = y(i);}
\StringTok{            closest_neighbor = i;}
\StringTok{        \}}
\StringTok{    \}}

\StringTok{    K = K - 1;}
\StringTok{    NN_distances(0) = closest_distance;}
\StringTok{    NN_classif(0) = closest_output;}
\StringTok{    distances(closest_neighbor) = 99999999999999999;}
\StringTok{    }
\StringTok{    int idx;}
\StringTok{    for (i = 0; i < K; i++) \{}
\StringTok{      double diff = 0;}
\StringTok{      double min_diff = 99999999999999999;}
\StringTok{      int index = 0;}
\StringTok{      for (idx = 0; idx < nrows; idx++) \{}
\StringTok{        diff = distances(idx) - NN_distances(i);}
\StringTok{        if (diff < min_diff) \{}
\StringTok{          min_diff = diff;}
\StringTok{          index = idx;}
\StringTok{        \}}
\StringTok{      \}}
\StringTok{      NN_distances(i+1) = distances(index);}
\StringTok{      NN_classif(i+1) = y(index);}
\StringTok{      distances(index) = 99999999999999999;}
\StringTok{    \}}
\StringTok{    }
\StringTok{    NumericVector classifs(unique(y).size());}
\StringTok{    for (i = 0; i < unique(y).size(); i++) \{}
\StringTok{      classifs[i] = i+1;}
\StringTok{    \}}

\StringTok{    NumericMatrix cnt(classifs.size(), 2);}
\StringTok{    for (i = 0; i < classifs.size(); i++) \{}
\StringTok{      cnt(i,0) = classifs(i);}
\StringTok{      cnt(i,1) = 0;}
\StringTok{    \}}
\StringTok{    for (i = 0; i < NN_classif.size(); i++) \{}
\StringTok{      cnt(NN_classif(i)-1,1) = cnt(NN_classif(i)-1,1) + 1;}
\StringTok{    \}}

\StringTok{    NumericVector count_vector = cnt(_,1);}
\StringTok{    NumericVector maxes = count_vector[count_vector == max(count_vector)];}
\StringTok{    int group = 0;}
\StringTok{    int group_normally = 0;}
\StringTok{    int maxes_size = maxes.size();}
\StringTok{    if (K <= classifs.size()) \{}
\StringTok{      if (maxes_size > 1) \{}
\StringTok{        for (i = 0; i < K; i++) \{}
\StringTok{          if (NN_distances(i) == min(NN_distances)) \{}
\StringTok{            group = NN_classif(i);}
\StringTok{          \}}
\StringTok{        \}}
\StringTok{      \} else \{}
\StringTok{        group_normally = 1;}
\StringTok{      \}}
\StringTok{    \} else \{}
\StringTok{      group_normally = 1;}
\StringTok{    \}}
\StringTok{    }
\StringTok{    if (group_normally == 1) \{}
\StringTok{      for (i = 0; i < classifs.size(); i++) \{}
\StringTok{        if (count_vector(i) == max(count_vector)) \{}
\StringTok{          group = i+1;}
\StringTok{        \}}
\StringTok{      \}}
\StringTok{    \}}

\StringTok{  return group;}
\StringTok{\}'}\NormalTok{)}
\NormalTok{test <-}\StringTok{ }\KeywordTok{knn_more}\NormalTok{(X, X0, y, }\DecValTok{3}\NormalTok{)}
\NormalTok{test}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
\end{verbatim}

\end{document}
